{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimental_analysis_IMDb_200725.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMJDARiId13yft4hwaghiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonas-jun/nlp_imdb_sentiment/blob/master/sentimental_analysis_IMDb_200725.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbvSylcsvqeG",
        "colab_type": "text"
      },
      "source": [
        "# **Simple Sentiment Analysis use IMDb dataset**\n",
        "\n",
        "following [bentrevett's github](https://github.com/bentrevett/pytorch-sentiment-analysis)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLnGKs86tYfL",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Datasets\n",
        "\n",
        "\n",
        "\n",
        "1.   Field 설정\n",
        "2.   데이터셋 다운로드\n",
        "3.   validation set 나누기\n",
        "\n",
        "\n",
        "\n",
        "    데이터 셋을 매번 다운로드 받지 않고 load할 수 있는 방법은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G6t0CTMs48x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets #download IMDb dataset\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time #check timedelta for an epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lJyW8fBtkuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 1\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "#Field의 기능?\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYZ7tO_2t6uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E7SxDa0xMx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of training examples: {}'.format(len(train_data)))\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLa5mU6KxTSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aFNzqG5xdA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split validation set\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(seed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6ZaHnyLxuii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of training examples: {}'.format(len(train_data)))\n",
        "print('Number of validation examples: {}'.format(len(valid_data)))\n",
        "print('Number of test examples: {}'.format(len(test_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XsDQw32xwq8",
        "colab_type": "text"
      },
      "source": [
        "## Make Vocabulary\n",
        "\n",
        "1.   max_vocab_size 지정\n",
        "    \n",
        "    그런데 25000개가 아닌 25002개가 잡히는 이유는?: unk와 pad가 존재한다.\n",
        "\n",
        "    sentence1: I hate this film.\n",
        "\n",
        "    sentence2: This film sucks < pad >\n",
        "2.   단어 빈도 분석 가능\n",
        "\n",
        "    vocab은 dictionary 형태로 되어 있으며, itos(int to str), stoi(s to i) 사용 가능\n",
        "\n",
        "\n",
        "\n",
        "    vocab 파일은 저장이 되나?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn3-DtJrx1vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_vocab_size = 25000\n",
        "TEXT.build_vocab(train_data, max_size=max_vocab_size)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print('Unique tokens in TEXT vocabulary: {}'.format(len(TEXT.vocab)))\n",
        "print('Unique tokens in LABEL vocabulary: {}'.format(len(LABEL.vocab)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9acFeR-ycfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCXdNjr2ydXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8nkNUeaym8K",
        "colab_type": "text"
      },
      "source": [
        "## Make Iterator\n",
        "\n",
        "    BucketIterator의 기능은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-rsa-CHygnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), batch_size=batch_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dD-Dusr7rbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae5d1c6e-598d-42b9-8c63-65c0744b8ddf"
      },
      "source": [
        "print('device: {}'.format(device))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIdNTaYgysfw",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "**Make RNN model**\n",
        "\n",
        "input dimension: lenth of one-hot vectors\n",
        "\n",
        "embedding dimension: the size of the dense word vectors, usually around 50-250 dimensions.\n",
        "\n",
        "hidden dimension: the size of the hidden states.\n",
        "\n",
        "output dimension: the number of classes. in this case 1, because only 2 cases, 0 or 1\n",
        "\n",
        "    assert와 squeeze(1)의 기능은?\n",
        "    embedding dim은 어떻게 정해지는지?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNFAMW_A0Wnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        assert torch.equal(output[-1, :, :], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhw7FWZs0wgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cvM23Un0w-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameteres(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('The model has {0:,} trainable parameters'.format(count_parameteres(model)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkeSkfgH1Dgb",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "\n",
        "\n",
        "1.   Optimizer 정의\n",
        "2.   Loss function 정의\n",
        "3. model과 loss 연산을 모두 device로 보내기\n",
        "4. train과 evaluate 함수 각각 정의\n",
        "5. training에 걸리는 시간 측정\n",
        "6. 실제로 트레이닝(여러 차례의 epochs)\n",
        "    \n",
        "    최적의 validation loss를 가진 parameters를 저장하여 이후 test set에 사용\n",
        "\n",
        "argument1: parameters we will update\n",
        "\n",
        "argument2: learning rate\n",
        "\n",
        "\n",
        "    최적의 parameter가 어디에 저장이 되는지?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wJ0OI511Oww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74I3A_PU2O0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make accuracy function\n",
        "def binary_accuracy(preds, y):\n",
        "    '''\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, not 8\n",
        "    '''\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #float for division\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYU1QtJR2ELZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vGjDJ-h16xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for validation: evaluation에서는 parameter 최적화 과정을 거치지 않아도 된다. (except backpropagation & optimizing)\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sLNmFiP39PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking time to compare training times between models\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plHrVUXP4HNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf') #무한대에서 조금씩 줄여가기\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt') # .pt 파일?\n",
        "\n",
        "    print('Epoch: {0:02} | Epoch Time: {1}m {2}s'.format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print('\\tTrain Loss: {0:0.3f} | Train Acc: {1:0.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {0:0.3f} |  Val. Acc: {1:0.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fLw0lx5ybF",
        "colab_type": "text"
      },
      "source": [
        "## Prediction with testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNfvhmrF5lXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk_13x848Jbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}